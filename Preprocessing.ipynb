{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Example\n",
    "\n",
    "This snippet is demonstrating the usage of the preprocessing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocessing import preprocess_data\n",
    "\n",
    "file, word_statistics, sentence_statistics = preprocess_data(\"./twitter-datasets/data/train_neg.txt\",\n",
    "                                                             unpack_hashtags=True,\n",
    "                                                             remove_duplicate_chars=True,\n",
    "                                                             dict_methods=True,\n",
    "                                                             removal_contractions=True,\n",
    "                                                             simplify_haha=True,\n",
    "                                                             replace_emoticons=True,\n",
    "                                                             remove_stopwords=False,\n",
    "                                                             lemmatize=False,\n",
    "                                                             stemming=False,\n",
    "                                                             replace_numbers=True)\n",
    "\n",
    "print(\"Total number of single words modified per option:\")\n",
    "print(word_statistics)\n",
    "print(\"Total number of sentences modified per option:\")\n",
    "print(sentence_statistics)\n",
    "print(\"Results of preprocessing are saved to:\")\n",
    "print(file.absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet demonstrates the usage of the sequence-to-sequence model for text normalization. The function used internally constructs a docker container and makes API calls to it to preprocess tweets. If this is taking too long, we recommend preprocessing the entire file containing all of the tweets by following instructions in the `preprocessing/seq2seq/README.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocessing import apply_S2S\n",
    "\n",
    "file = apply_S2S(\"./twitter-datasets/data/train_neg_mini.txt\")\n",
    "with file.open() as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
